{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install requests beautifulsoup4\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:55:31.911481Z","iopub.execute_input":"2023-12-20T16:55:31.911826Z","iopub.status.idle":"2023-12-20T16:55:43.736219Z","shell.execute_reply.started":"2023-12-20T16:55:31.911798Z","shell.execute_reply":"2023-12-20T16:55:43.734604Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2023.11.17)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install openai\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:55:43.738282Z","iopub.execute_input":"2023-12-20T16:55:43.738559Z","iopub.status.idle":"2023-12-20T16:56:07.642534Z","shell.execute_reply.started":"2023-12-20T16:55:43.738534Z","shell.execute_reply":"2023-12-20T16:56:07.641637Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/07/de/ef3534d9417f7c72c75036fae6c85d9071aebbce8aa3616d3e69b9f0ca4d/openai-1.6.0-py3-none-any.whl.metadata\n  Downloading openai-1.6.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.8.0)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.10.12)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nCollecting typing-extensions<5,>=4.7 (from openai)\n  Obtaining dependency information for typing-extensions<5,>=4.7 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nDownloading openai-1.6.0-py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\nInstalling collected packages: typing-extensions, httpcore, httpx, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Uninstalling typing_extensions-4.5.0:\n      Successfully uninstalled typing_extensions-4.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.1 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed httpcore-1.0.2 httpx-0.26.0 openai-1.6.0 typing-extensions-4.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport requests\nfrom bs4 import BeautifulSoup\nimport openai \nimport time\n\n# Set OpenAI API key\nopenai.api_key = 'your_openai_api_key'\n\n# Function to generate a personalized message using OpenAI's text generation\ndef generate_personalized_message(profile_data):\n    # Construct prompt for the OpenAI API\n    prompt = f\"Generate a personalized connection request message for a LinkedIn profile. Profile details:\\n{profile_data}\"\n    \n    # Call OpenAI API for text generation\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        max_tokens=150,\n        temperature=0.7,\n        n=1,\n    )\n    # Extract and return the generated message\n    message = response['choices'][0]['text'].strip()\n    return message\n\n# Function to log in to LinkedIn\ndef login_linkedin(username, password):\n    # Define LinkedIn login URL and set headers\n    login_url = \"https://www.linkedin.com/login\"\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n    }\n    # Create a session and initiate a GET request to the login page\n    session = requests.Session()\n    response = session.get(login_url, headers=headers)\n    \n    # Parse the response to extract CSRF token\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    csrf_token = soup.find(\"input\", {\"name\": \"loginCsrfParam\"}).get(\"value\")\n\n    # Construct login payload\n    login_payload = {\n        \"session_key\": username,\n        \"session_password\": password,\n        \"loginCsrfParam\": csrf_token,\n    }\n\n    # Perform POST request to log in\n    session.post(login_url, data=login_payload, headers=headers)\n    return session\n\n# Function to retrieve new connections from a LinkedIn profile\ndef get_new_connections(session, competitor_profile_url):\n    # Perform GET request to retrieve competitor's profile\n    competitor_profile = session.get(competitor_profile_url)\n    competitor_soup = BeautifulSoup(competitor_profile.content, \"html.parser\")\n\n    # Extract connection elements from the HTML\n    connection_elements = competitor_soup.find_all(\"li\", class_=\"mn-connection-card\")\n    \n    # Extract and return connection URLs\n    new_connections = [connection.find(\"a\")[\"href\"] for connection in connection_elements]\n    return new_connections\n\n# Function to analyze a LinkedIn profile\ndef analyze_profile(session, connection_url):\n    # Perform GET request to retrieve connection's profile\n    connection_profile = session.get(connection_url)\n    connection_soup = BeautifulSoup(connection_profile.content, \"html.parser\")\n\n    # Extract 'About' section text\n    about_section = connection_soup.find(\"section\", class_=\"pv-about-section\")\n    about_text = about_section.find(\"p\").text.strip() if about_section else \"No 'About' section available.\"\n\n    # Extract job description from 'Experience' section\n    experience_section = connection_soup.find(\"section\", class_=\"experience-section\")\n    job_description = experience_section.text.strip() if experience_section else \"No job description available.\"\n\n    # Extract recent posts from the 'Posts' section\n    posts_section = connection_soup.find(\"section\", class_=\"core-rail\")\n    recent_posts = [post.text.strip() for post in posts_section.find_all(\"div\", class_=\"occludable-update\")]\n\n    # Return a dictionary with analyzed profile data\n    return {\n        \"About\": about_text,\n        \"Job Description\": job_description,\n        \"Recent Posts\": recent_posts,\n    }\n\n# Function to send a connection request on LinkedIn\ndef send_connection_request(session, connection_url, personalized_message):\n    # Extract user's ID from the connection URL\n    user_id = connection_url.split(\"/\")[-1]\n\n    # Construct URL for sending connection request\n    connection_request_url = f\"https://www.linkedin.com/voyager/api/relationships/connect?resId={user_id}\"\n    request_data = {\n        'message': personalized_message,\n        'trackingId': f'contact-{user_id}',\n    }\n    # Perform POST request to send the connection request\n    session.post(connection_request_url, json=request_data)\n\n# Example usage\ncompetitor_username = \"your_competitor_username\"\ncompetitor_password = \"your_competitor_password\"\ncompetitor_profile_url = \"https://www.linkedin.com/in/competitor_profile\"\n\n# Log in to LinkedIn using provided credentials\nsession = login_linkedin(competitor_username, competitor_password)\n\n# Retrieve new connections from the competitor's profile\nnew_connections = get_new_connections(session, competitor_profile_url)\n\n# Introduce a delay to avoid potential issues with LinkedIn's rate limiting\ntime.sleep(2)\n\n# Iterate over new connections and perform analysis, generate personalized messages, and send connection requests\nfor connection_url in new_connections:\n    # Analyze the profile of each connection\n    profile_data = analyze_profile(session, connection_url)\n    print(f\"Analysis for {connection_url}:\")\n    print(profile_data)\n\n    # Generate a personalized connection request message\n    personalized_message = generate_personalized_message(profile_data)\n    print(f\"Generated Message: {personalized_message}\")\n\n    # Send the connection request with the personalized message\n    send_connection_request(session, connection_url, personalized_message)\n    print(f\"Connection request sent to {connection_url} with the personalized message.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:56:07.643792Z","iopub.execute_input":"2023-12-20T16:56:07.644141Z","iopub.status.idle":"2023-12-20T16:56:10.642277Z","shell.execute_reply.started":"2023-12-20T16:56:07.644101Z","shell.execute_reply":"2023-12-20T16:56:10.641501Z"},"trusted":true},"execution_count":3,"outputs":[]}]}